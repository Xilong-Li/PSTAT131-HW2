---
title: "HW2 PSTAT131"
author: "Xilong Li"
date: '2022-04-10'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidymodels)
library(tidyverse)
library(ggplot2)
# useless
abalone <- read.csv("abalone.csv")
head(abalone)
dim(abalone)
```


## Question 1:
```{r}
abalone<-
  abalone %>% 
  mutate(age = rings + 1.5) %>% 
  select(age, everything())
head(abalone)

abalone %>% 
  ggplot(aes(x = age)) +
  geom_histogram()

```
As the histogram shown above, the distribution of age is approximately normal, with a tail on the right.        
And most of the abalone has the age around 10 in this data set.

## QUestion 2:
```{r}
set.seed(2216)

abalone_split <- initial_split(abalone, prop = 0.80)
abalone_train <- training(abalone_split)
abalone_test <- testing(abalone_split)
dim(abalone_train)
dim(abalone_test)
```
## Question 3:
```{r}
head(abalone)
abalone_recipe <-
  recipe(age ~ 
           type + 
           longest_shell + 
           diameter + height + 
           whole_weight + 
           shucked_weight + 
           viscera_weight + 
           shell_weight, 
         data = abalone_train) %>% 
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(~ starts_with("type"):shucked_weight) %>% 
  step_interact(~ longest_shell:diameter) %>% 
  step_interact(~ shucked_weight:shell_weight) %>% 
  step_normalize()

abalone_recipe 

# We should not include the predictor "rings", 
# because the data of age is directly derived from rings;
# Thus, the training data would be 100% compatible with the testing data on the predictor of "rings"

```

## QUestion 4:
```{r}
lm_model <- linear_reg() %>% 
  set_engine("lm")

#code is cited from lab2
```

## Question 5:
```{r}
lm_wflow <- workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(abalone_recipe) 

lm_fit <- fit(lm_wflow, abalone_train)

lm_fit %>% 
  # This returns the parsnip object:
  extract_fit_parsnip() %>% 
  # Now tidy the linear model object:
  tidy()

#code is cited from lab2
```

## QUestion 6:
```{r}

# not yet finished
```

## QUestion 7:
```{r}
abalone_train_res <- predict(lm_fit, new_data = abalone_train %>% select(-age))
abalone_train_res %>% 
  head()

abalone_train_res <- bind_cols(abalone_train_res, abalone_train %>% select(age))
abalone_train_res %>% 
  head()

abalone_metrics <- metric_set(rmse, rsq, mae)
abalone_metrics(abalone_train_res, truth = age, 
                estimate = .pred)
```
R-Squared means the proportion of the variance for a dependent variable that's explained by an independent variable or variables in a regression model.(cited from https://www.investopedia.com/terms/r/r-squared.asp)        
Therefore, since the value of R-squared is 0.5639424, this means that 56.39424% of the response variable can be explained by predictor variables. 


